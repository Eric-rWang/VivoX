{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfTsTYF683q31mqqqf8D4w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eric-rWang/VivoX/blob/main/PPG_Lightweight_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lightweight Transformer Implementation"
      ],
      "metadata": {
        "id": "yVAlVS-Ko9Rw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugXQ1rxxo7eO"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import os\n",
        "import h5py\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Architecture:**\n",
        "\n",
        "**Input:**\n",
        "(batch_size, 1, 36, window_size) (36 channels: 12 locations × 3 wavelengths)\n",
        "\n",
        "**Channel-wise Embedding:**\n",
        "Stack of 1D convolutions and pooling compresses each channel’s temporal waveform into a single 256-dimensional feature vector.\n",
        "\n",
        "**Transformer Encoder:**\n",
        "A 2-layer Transformer encoder (with 4 attention heads) models relationships between these compressed features.\n",
        "\n",
        "**Regression Head:**\n",
        "Fully connected layers map the output to 2 values (SvO2 and SaO2).\n",
        "\n",
        "**Flow:**\n",
        "Input → Conv1d/Pooling → Feature Vector → Transformer → Output Head → Prediction"
      ],
      "metadata": {
        "id": "fcdq4Y6gpGyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LightweightTransformer(nn.Module):\n",
        "    def __init__(self, num_channels=36, window_size=350):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1. Channel-wise embedding with proper output dimension\n",
        "        self.embed = nn.Sequential(\n",
        "            nn.Conv1d(num_channels, 64, kernel_size=7, padding=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "\n",
        "        # 2. Transformer\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=256,\n",
        "            nhead=4,\n",
        "            dim_feedforward=512,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "\n",
        "        # 3. Output head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input: (B, 1, C, T)\n",
        "        x = x.squeeze(1)  # (B, C, T)\n",
        "        x = self.embed(x)  # (B, 256, 1)\n",
        "        x = x.squeeze(-1)  # (B, 256)\n",
        "        x = x.unsqueeze(1)  # (B, 1, 256)\n",
        "        x = self.transformer(x)  # (B, 1, 256)\n",
        "        x = x.squeeze(1)  # (B, 256)\n",
        "        return self.head(x)"
      ],
      "metadata": {
        "id": "VxX9dA5IpK8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supporting functions for script\n"
      ],
      "metadata": {
        "id": "SKq9w6V_ptQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_model(model):\n",
        "    model.eval()\n",
        "    try:\n",
        "        # Test with random data matching our expected input shape\n",
        "        dummy_input = torch.randn(2, 1, 36, 350)\n",
        "        output = model(dummy_input)\n",
        "        assert output.shape == (2, 2), f\"Bad output shape: {output.shape}\"\n",
        "        print(f\"Model verification passed\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Model verification failed: {str(e)}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "FSuM4ExkpwHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_h5py(file_path):\n",
        "    with h5py.File(file_path, 'r') as f:\n",
        "        X = f['waveforms'][:]\n",
        "        y = f['labels'][:]\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "bsxrijWIpzd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurations"
      ],
      "metadata": {
        "id": "xHt8fR0aqB65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USE_SEPARATE_TEST_FILE = True  # Set to False to use single file approach\n",
        "\n",
        "if USE_SEPARATE_TEST_FILE:\n",
        "    train_val_file_path = \"DATA/JUL22_recordings.h5\"\n",
        "    test_file_path = \"DATA/JUL22_test.h5\"\n",
        "    print(f\"Loading training/validation data from {train_val_file_path} ...\")\n",
        "    print(f\"Loading test data from {test_file_path} ...\")\n",
        "else:\n",
        "    file_path = \"DATA/jul14th_shift_sensor_data_eric.h5\"\n",
        "    print(f\"Loading data from {file_path} ...\")"
      ],
      "metadata": {
        "id": "wWbL8jV1qD5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model hyperparameters"
      ],
      "metadata": {
        "id": "0zaWh6NxqJp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "num_channels = 36\n",
        "window_size = 350\n",
        "batch_size = 32\n",
        "lr = 1e-4\n",
        "weight_decay = 1e-4\n",
        "num_epochs = 5 # was 300\n",
        "n_patience = 50\n",
        "\n",
        "# Models to train\n",
        "MODELS = {\n",
        "    \"LightTransformer\": LightweightTransformer\n",
        "}"
      ],
      "metadata": {
        "id": "PhjULJ8CqL6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loading and preparation"
      ],
      "metadata": {
        "id": "Wqz8KUYSqWuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Loading and Preparation ---\n",
        "if USE_SEPARATE_TEST_FILE:\n",
        "    # Load training/validation data\n",
        "    combined_data, labels_array = import_h5py(train_val_file_path)\n",
        "    print(f\"Training/Val data loaded ✅\\nData shape: {combined_data.shape}, Labels shape: {labels_array.shape}\")\n",
        "\n",
        "    # Load test data separately\n",
        "    X_test, y_test = import_h5py(test_file_path)\n",
        "    print(f\"Test data loaded ✅\\nData shape: {X_test.shape}, Labels shape: {y_test.shape}\")\n",
        "\n",
        "    # Split the training/validation data into train and val (75/25 split)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        combined_data, labels_array,\n",
        "        test_size=0.25,\n",
        "        random_state=42\n",
        "    )\n",
        "else:\n",
        "    # Original single file approach\n",
        "    combined_data, labels_array = import_h5py(file_path)\n",
        "    print(f\"Loaded ✅\\nData shape: {combined_data.shape}, Labels shape: {labels_array.shape}\")\n",
        "\n",
        "    # Use 100% of combined_data: 60% train, 20% val, 20% test\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        combined_data, labels_array,\n",
        "        train_size=0.6,\n",
        "        random_state=42\n",
        "    )\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp,\n",
        "        test_size=0.5,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "print(\"Training data range:\")\n",
        "print(f\"X_train: {X_train.min()} to {X_train.max()}\")\n",
        "print(f\"y_train: {y_train.min()} to {y_train.max()}\")\n",
        "print(\"\\nTest data range:\")\n",
        "print(f\"X_test: {X_test.min()} to {X_test.max()}\")\n",
        "print(f\"y_test: {y_test.min()} to {y_test.max()}\")"
      ],
      "metadata": {
        "id": "X4pexdl4qYpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diagnostic"
      ],
      "metadata": {
        "id": "hUViPrxGqnff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagnostic: original train‐set class counts\n",
        "print(f\"\\nOriginal training set class counts:\")\n",
        "labels, counts = np.unique(y_train, axis=0, return_counts=True)\n",
        "for lbl, cnt in zip(labels, counts):\n",
        "    print(f\"  {lbl.tolist()}: {cnt} samples\")"
      ],
      "metadata": {
        "id": "_0eF0YPJqpD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balancing"
      ],
      "metadata": {
        "id": "LXZZNnANqq8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Balance TRAINING SET only via median‐based under/oversampling ---\n",
        "target = int(np.median(counts))\n",
        "print(f\"\\nBalancing training set to {target} samples per class (median count)\")\n",
        "balanced_X, balanced_y = [], []\n",
        "\n",
        "def jitter(x, σ=0.02):\n",
        "    return x + np.random.normal(0, σ*np.std(x), size=x.shape)\n",
        "def time_shift(x, max_shift=15):\n",
        "    s = np.random.randint(-max_shift, max_shift+1)\n",
        "    return np.roll(x, s, axis=0)\n",
        "\n",
        "for lbl, cnt in zip(labels, counts):\n",
        "    idxs = np.where((y_train == lbl).all(axis=1))[0]\n",
        "    X_lbl = X_train[idxs]\n",
        "    y_lbl = y_train[idxs]\n",
        "    # undersample if too big\n",
        "    if cnt > target:\n",
        "        chosen = np.random.choice(idxs, target, replace=False)\n",
        "        balanced_X.append(X_train[chosen])\n",
        "        balanced_y.append(y_train[chosen])\n",
        "    # oversample + augment if too small\n",
        "    elif cnt < target:\n",
        "        balanced_X.append(X_lbl)\n",
        "        balanced_y.append(y_lbl)\n",
        "        n_to_gen = target - cnt\n",
        "        for _ in range(n_to_gen):\n",
        "            i = np.random.choice(idxs)\n",
        "            x_aug = time_shift(jitter(X_train[i]))\n",
        "            balanced_X.append(x_aug[None])\n",
        "            balanced_y.append(lbl[None])\n",
        "    else:\n",
        "        balanced_X.append(X_lbl)\n",
        "        balanced_y.append(y_lbl)\n",
        "\n",
        "# concatenate back\n",
        "X_train = np.vstack(balanced_X)\n",
        "y_train = np.vstack(balanced_y)"
      ],
      "metadata": {
        "id": "9EUkx-XGqsT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post balancing diagnostic"
      ],
      "metadata": {
        "id": "mB8hBmpkq9Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagnostic: neue training und test set Klassenquantitäten\n",
        "print(\"Post‐balance training set class counts:\")\n",
        "new_labels, new_counts = np.unique(y_train, axis=0, return_counts=True)\n",
        "for lbl, old_cnt, new_cnt in zip(labels, counts, new_counts):\n",
        "    delta = new_cnt - old_cnt\n",
        "    pct = delta/old_cnt*100\n",
        "    print(f\"  {lbl.tolist()}: {new_cnt} samples ({'+' if delta>=0 else ''}{delta}, {pct:.1f}%)\")"
      ],
      "metadata": {
        "id": "6vHYEncBq4sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization\n"
      ],
      "metadata": {
        "id": "vfr2KE_zq_ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Better input normalization (per‐channel)\n",
        "def normalize_ppg(X):\n",
        "    median = np.median(X, axis=2, keepdims=True)\n",
        "    mad    = 1.4826 * np.median(np.abs(X - median), axis=2, keepdims=True)\n",
        "    return (X - median) / (mad + 1e-6)\n",
        "\n",
        "X_train = normalize_ppg(X_train)\n",
        "X_val   = normalize_ppg(X_val)\n",
        "X_test  = normalize_ppg(X_test)\n",
        "\n",
        "# Label normalization\n",
        "y_max   = 100.0\n",
        "y_train = y_train / y_max\n",
        "y_val   = y_val   / y_max\n",
        "y_test  = y_test  / y_max\n",
        "\n",
        "print(\"Post-scaling X range:\", X_train.min(), X_train.max())\n",
        "print(\"Post-scaling y range:\", y_train.min(), y_train.max())"
      ],
      "metadata": {
        "id": "lWtsBszLrDrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the splits for later\n",
        "np.savez(os.path.join(save_dir, 'data_splits.npz'),\n",
        "         X_train=X_train, y_train=y_train,\n",
        "         X_val=X_val,     y_val=y_val,\n",
        "         X_test=X_test,   y_test=y_test)"
      ],
      "metadata": {
        "id": "Mpc5sJQRrGPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensors and reshape\n",
        "X_train_t = torch.from_numpy(X_train).float()\n",
        "y_train_t = torch.from_numpy(y_train).float()\n",
        "X_val_t = torch.from_numpy(X_val).float()\n",
        "y_val_t = torch.from_numpy(y_val).float()\n",
        "X_test_t = torch.from_numpy(X_test).float()\n",
        "y_test_t = torch.from_numpy(y_test).float()"
      ],
      "metadata": {
        "id": "9rvTSN8zrKGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape to (N, 1, 36, 350)\n",
        "X_train_rs = X_train_t.permute(0, 2, 1).unsqueeze(1)\n",
        "X_val_rs = X_val_t.permute(0, 2, 1).unsqueeze(1)\n",
        "X_test_rs = X_test_t.permute(0, 2, 1).unsqueeze(1)"
      ],
      "metadata": {
        "id": "VQbdQyCUrPsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize using only training statistics und so\n",
        "mean = X_train_rs.mean(dim=(0, 1, 3), keepdim=True)\n",
        "std = X_train_rs.std(dim=(0, 1, 3), keepdim=True)\n",
        "X_train_rs = (X_train_rs - mean) / (std + 1e-6)\n",
        "X_val_rs = (X_val_rs - mean) / (std + 1e-6)\n",
        "X_test_rs = (X_test_rs - mean) / (std + 1e-6)"
      ],
      "metadata": {
        "id": "YeuI_JVJrRr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoaders\n",
        "train_loader = DataLoader(TensorDataset(X_train_rs, y_train_t), batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val_rs, y_val_t), batch_size=batch_size)\n",
        "test_loader = DataLoader(TensorDataset(X_test_rs, y_test_t), batch_size=batch_size)"
      ],
      "metadata": {
        "id": "GuAsOMMjrTPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training Loop für alle Modelle ---\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"🚀 Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"🍏 Using Apple Silicon GPU (MPS)\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"💀 Falling back to CPU? Yikes!\")\n",
        "\n",
        "for model_name, model_class in MODELS.items():\n",
        "\n",
        "    print(f\"\\n=== Training {model_name} ===\")\n",
        "    model = model_class(\n",
        "        num_channels=num_channels,\n",
        "        window_size=window_size\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    test_losses = []  # für jede epoch den test loss speichern aber halt auch den g\n",
        "    epoch_times = []  # Track epoch durations\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        epoch_train_loss = 0.0\n",
        "        for Xb, yb in train_loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(Xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            epoch_train_loss += loss.item() * Xb.size(0)\n",
        "        train_losses.append(epoch_train_loss / len(train_loader.dataset))\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        epoch_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for Xb, yb in val_loader:\n",
        "                Xb, yb = Xb.to(device), yb.to(device)\n",
        "                epoch_val_loss += criterion(model(Xb), yb).item() * Xb.size(0)\n",
        "        val_losses.append(epoch_val_loss / len(val_loader.dataset))\n",
        "\n",
        "        # TEST PHASE - NOW EVALUATED EVERY EPOCH\n",
        "        epoch_test_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for Xb, yb in test_loader:\n",
        "                Xb, yb = Xb.to(device), yb.to(device)\n",
        "                epoch_test_loss += criterion(model(Xb), yb).item() * Xb.size(0)\n",
        "        test_losses.append(epoch_test_loss / len(test_loader.dataset))\n",
        "\n",
        "        # Calculate epoch duration and ETA; einfach nur für den aktuellen Epoch\n",
        "        epoch_duration = time.time() - epoch_start_time\n",
        "        epoch_times.append(epoch_duration)\n",
        "\n",
        "        # Calculate ETA based on average epoch time\n",
        "        avg_epoch_time = np.mean(epoch_times)\n",
        "        remaining_epochs = num_epochs - epoch\n",
        "        eta_seconds = remaining_epochs * avg_epoch_time\n",
        "        eta_mins = eta_seconds / 60\n",
        "\n",
        "        # Update scheduler and early stopping\n",
        "        scheduler.step(val_losses[-1])\n",
        "        if val_losses[-1] < best_val_loss:\n",
        "            best_val_loss = val_losses[-1]\n",
        "            patience_counter = 0\n",
        "            status = ''\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            status = '⚪️'\n",
        "            if patience_counter >= n_patience:\n",
        "                print(f\"\\nEarly stopping triggered at epoch {epoch}!\")\n",
        "                break\n",
        "\n",
        "        print(f\"{status} {model_name} Epoch {epoch:3d}: Train {train_losses[-1]:.4f} | Val {val_losses[-1]:.4f} | Test {test_losses[-1]:.4f} | {epoch_duration:.1f}s/epoch | ETA: {eta_mins:.1f}mins ({eta_seconds:.0f}s)\")\n",
        "\n",
        "    print(f\"\\n{model_name} Training complete!\")\n",
        "    print(f\"Best val loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    # Save model and training history\n",
        "    torch.save({\n",
        "        'model_state': model.state_dict(),\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'test_losses': test_losses,  # Full test loss trajectory - weil wir es jetzt jedes Epoch speichern\n",
        "        'config': {\n",
        "            'num_channels': num_channels,\n",
        "            'window_size': window_size,\n",
        "            'model_name': model_name\n",
        "        }\n",
        "    }, os.path.join(save_dir, f'{model_name}.pt'))\n",
        "\n",
        "print(\"\\nAll models trained and saved!\")"
      ],
      "metadata": {
        "id": "1DOGZRxurN93"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}