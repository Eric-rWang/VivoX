{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eric-rWang/VivoX/blob/main/PPG_VivoX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PNnmqXCt43U",
        "outputId": "42b79463-dd5a-42db-bfa7-ad0c33ddc709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PPG ML\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import h5py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "os.chdir(\"/content/PPG ML\")\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U9WdLqoS3XT"
      },
      "source": [
        "VivoX transformer model:\n",
        "<ul>\n",
        "<li>Linear projection from flattened window inputs to d_model</li>\n",
        "<li>Sinusoidal positional encodings</li>\n",
        "<li>Standard encoder stack</li>\n",
        "<li>Mean pooling and MLP head for arterial and venous regression</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXdPytBLS2O2"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements sinusoidal positional encoding.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
        "                             (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # shape (1, max_len, d_model)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor of shape (batch_size, seq_len, d_model)\n",
        "        Returns:\n",
        "            Tensor: (batch_size, seq_len, d_model) with positional encoding added\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x\n",
        "\n",
        "\n",
        "class vivoxTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple Transformer model for arterial & venous SpO2 prediction from multichannel PPG.\n",
        "\n",
        "    Args:\n",
        "        num_channels: number of input channels (e.g., 36)\n",
        "        window_size: number of time samples per window (e.g., 350)\n",
        "        d_model: embedding dimension\n",
        "        nhead: number of attention heads\n",
        "        num_layers: number of Transformer encoder layers\n",
        "        dim_feedforward: dimension of the MLP in encoder layers\n",
        "        dropout: dropout rate\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_channels: int = 36,\n",
        "        window_size: int = 350,\n",
        "        d_model: int = 128,\n",
        "        nhead: int = 4,\n",
        "        num_layers: int = 3,\n",
        "        dim_feedforward: int = 512,\n",
        "        dropout: float = 0.3, # Increased from 0.1\n",
        "        max_windows: int = 200,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        input_dim = num_channels * window_size\n",
        "\n",
        "        # 1) Linear projection of each window to d_model\n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "        self.input_norm = nn.LayerNorm(d_model) # Normalize\n",
        "\n",
        "        # 2) Positional encoding for up to max_windows\n",
        "        self.pos_enc = PositionalEncoding(d_model, max_len=max_windows)\n",
        "\n",
        "        # 3) Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True  # allows (batch, seq, feature)\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "\n",
        "        # 4) Regression head for arterial & venous SpO2\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model // 2, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor of shape (batch_size, num_windows, num_channels, window_size)\n",
        "        Returns:\n",
        "            Tensor of shape (batch_size, 2) containing [SpO2_art, SpO2_ven]\n",
        "        \"\"\"\n",
        "        batch, num_windows, C, W = x.size()\n",
        "        # Flatten channels & time\n",
        "        x = x.view(batch, num_windows, C * W)             # (batch, num_windows, input_dim)\n",
        "\n",
        "        # Embed\n",
        "        x = self.input_proj(x)                           # (batch, num_windows, d_model)\n",
        "\n",
        "        # Normalize\n",
        "        x = self.input_norm(x)\n",
        "\n",
        "        # Add positional encoding\n",
        "        x = self.pos_enc(x)                              # (batch, num_windows, d_model)\n",
        "\n",
        "        # Transformer encoding\n",
        "        x = self.transformer(x)                          # (batch, num_windows, d_model)\n",
        "\n",
        "        # Pool across time windows\n",
        "        rep = x.mean(dim=1)                              # (batch, d_model)\n",
        "\n",
        "        # Predict SpO2\n",
        "        out = self.head(rep)                             # (batch, 2)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USXvnJ2zuagH"
      },
      "source": [
        "Loading in data set from phantom setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvwTXMWBufVy"
      },
      "outputs": [],
      "source": [
        "def import_h5py(file_path):\n",
        "  with h5py.File(file_path, 'r') as f:\n",
        "      X = f['waveforms'][:]\n",
        "      y = f['labels'][:]\n",
        "\n",
        "      return X, y\n",
        "\n",
        "file_path = \"Shifting_Position.h5\"\n",
        "combined_data, labels_array = import_h5py(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2g9qTNCxtxE"
      },
      "source": [
        "Splitting imported dataset into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUn-ftNrx2qf",
        "outputId": "e5691401-1f7d-4efb-afd2-d98313105e36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (1278, 350, 36)\n",
            "X_test  shape: (320, 350, 36)\n"
          ]
        }
      ],
      "source": [
        "labels_df = pd.DataFrame(\n",
        "        labels_array,\n",
        "        columns=['arterial_saturation', 'venous_saturation']\n",
        ")\n",
        "\n",
        "# Split into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    combined_data, labels_array, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Print out shape of train and test data\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test  shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwNol1BLyguH"
      },
      "source": [
        "Training CNN function. Setting epoch to 500 for now. Since channels of data have their own unique position, we add positional as well as wavelength embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0hhMbqozGIN"
      },
      "outputs": [],
      "source": [
        "save_path = 'vivoxTransformer.pth'\n",
        "\n",
        "# --- Hyperparameters & settings ---\n",
        "num_channels = 36\n",
        "window_size  = 350\n",
        "d_model      = 128\n",
        "batch_size   = 16\n",
        "lr           = 1e-4\n",
        "weight_decay = 5e-4\n",
        "num_epochs   = 1000\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Convert NumPy to torch tensors (no permute needed; model expects (B, T, C))\n",
        "X_train_t = torch.from_numpy(X_train).float()\n",
        "y_train_t = torch.from_numpy(y_train).float()\n",
        "X_test_t  = torch.from_numpy(X_test).float()\n",
        "y_test_t  = torch.from_numpy(y_test).float()\n",
        "\n",
        "# 2) permute & unsqueeze so each sample is (1 window, 36 channels, 350 timesteps)\n",
        "#    result: (N, 1, 36, 350)\n",
        "X_train_rs = X_train_t.permute(0, 2, 1).unsqueeze(1)\n",
        "X_test_rs  = X_test_t .permute(0, 2, 1).unsqueeze(1)\n",
        "# assuming X_train_rs is (N,1,36,350)\n",
        "mean = X_train_rs.mean(dim=(0,1,3), keepdim=True)  # per-channel mean\n",
        "std  =  X_train_rs.std(dim=(0,1,3), keepdim=True)  # per-channel std\n",
        "X_train_rs = (X_train_rs - mean) / (std + 1e-6)\n",
        "X_test_rs  = (X_test_rs  - mean) / (std + 1e-6)\n",
        "\n",
        "# 3) DataLoaders\n",
        "train_loader = DataLoader(TensorDataset(X_train_rs, y_train_t),\n",
        "                          batch_size=batch_size, shuffle=True)\n",
        "test_loader  = DataLoader(TensorDataset(X_test_rs,  y_test_t),\n",
        "                          batch_size=batch_size)"
      ],
      "metadata": {
        "id": "69iLiWg68W9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqyCrCHpT8DG"
      },
      "outputs": [],
      "source": [
        "# 2) Model Setup\n",
        "model = vivoxTransformer(\n",
        "            num_channels=num_channels,\n",
        "            window_size=window_size,\n",
        "            d_model=d_model\n",
        "        ).to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8uii8lU0T-Dl",
        "outputId": "34b6e652-08e8-488c-cd4d-0e347a0ee887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training Loop\n",
            "Epoch   1: Train 3164.4523, Test 2994.5166 → saved best\n",
            "Epoch   2: Train 2831.7640, Test 2640.4046 → saved best\n",
            "Epoch   3: Train 2437.3317, Test 2196.3625 → saved best\n",
            "Epoch   4: Train 1972.9793, Test 1713.6671 → saved best\n",
            "Epoch   5: Train 1497.5934, Test 1248.1099 → saved best\n",
            "Epoch   6: Train 1063.4799, Test 854.1872 → saved best\n",
            "Epoch   7: Train 719.1559, Test 561.8248 → saved best\n",
            "Epoch   8: Train 473.2084, Test 362.4142 → saved best\n",
            "Epoch   9: Train 309.5993, Test 236.3726 → saved best\n",
            "Epoch  10: Train 211.4902, Test 166.3790 → saved best\n",
            "Epoch  11: Train 160.2306, Test 133.6652 → saved best\n",
            "Epoch  12: Train 137.6934, Test 120.8946 → saved best\n",
            "Epoch  13: Train 128.8957, Test 116.8021 → saved best\n",
            "Epoch  14: Train 125.9962, Test 115.7670 → saved best\n",
            "Epoch  15: Train 127.4444, Test 115.6891 \n",
            "Epoch  16: Train 124.0436, Test 111.6985 → saved best\n",
            "Epoch  17: Train 105.0194, Test 79.0874 → saved best\n",
            "Epoch  18: Train 67.4638, Test 43.9881 → saved best\n",
            "Epoch  19: Train 37.3096, Test 28.4596 → saved best\n",
            "Epoch  20: Train 29.1766, Test 34.3699 → saved best\n",
            "Epoch  21: Train 29.1905, Test 26.2689 \n",
            "Epoch  22: Train 27.6326, Test 25.9440 → saved best\n",
            "Epoch  23: Train 26.4398, Test 24.1978 → saved best\n",
            "Epoch  24: Train 25.4859, Test 23.2243 → saved best\n",
            "Epoch  25: Train 23.8653, Test 21.9832 → saved best\n",
            "Epoch  26: Train 22.9202, Test 20.9938 → saved best\n",
            "Epoch  27: Train 22.0702, Test 20.0418 → saved best\n",
            "Epoch  28: Train 21.1806, Test 19.0111 → saved best\n",
            "Epoch  29: Train 20.3034, Test 18.2838 → saved best\n",
            "Epoch  30: Train 19.0028, Test 16.6314 → saved best\n",
            "Epoch  31: Train 17.5166, Test 15.2820 → saved best\n",
            "Epoch  32: Train 16.1146, Test 14.7675 → saved best\n",
            "Epoch  33: Train 15.2010, Test 13.2828 → saved best\n",
            "Epoch  34: Train 14.5744, Test 13.7825 → saved best\n",
            "Epoch  35: Train 13.9315, Test 12.5249 → saved best\n",
            "Epoch  36: Train 13.6707, Test 12.0936 → saved best\n",
            "Epoch  37: Train 13.6212, Test 12.0272 → saved best\n",
            "Epoch  38: Train 13.3162, Test 11.8973 → saved best\n",
            "Epoch  39: Train 13.1390, Test 12.1755 → saved best\n",
            "Epoch  40: Train 12.8017, Test 11.4763 → saved best\n",
            "Epoch  41: Train 12.4770, Test 11.1067 → saved best\n",
            "Epoch  42: Train 12.1928, Test 10.7562 → saved best\n",
            "Epoch  43: Train 11.7328, Test 9.9871 → saved best\n",
            "Epoch  44: Train 11.0489, Test 9.3420 → saved best\n",
            "Epoch  45: Train 10.0146, Test 8.5141 → saved best\n",
            "Epoch  46: Train 9.4312, Test 7.1796 → saved best\n",
            "Epoch  47: Train 8.3557, Test 6.6291 → saved best\n",
            "Epoch  48: Train 7.3944, Test 5.8123 → saved best\n",
            "Epoch  49: Train 6.3873, Test 4.7846 → saved best\n",
            "Epoch  50: Train 5.3948, Test 3.9630 → saved best\n",
            "Epoch  51: Train 4.2830, Test 3.3859 → saved best\n",
            "Epoch  52: Train 3.4859, Test 2.6109 → saved best\n",
            "Epoch  53: Train 2.5646, Test 2.1675 → saved best\n",
            "Epoch  54: Train 4.4897, Test 63.0023 \n",
            "Epoch  55: Train 45.1163, Test 20.7581 \n",
            "Epoch  56: Train 4.4809, Test 3.3918 \n",
            "Epoch  57: Train 2.3138, Test 2.5514 → saved best\n",
            "Epoch  58: Train 1.5667, Test 2.0225 → saved best\n",
            "Epoch  59: Train 1.1025, Test 1.5330 → saved best\n",
            "Epoch  60: Train 0.7711, Test 1.4507 → saved best\n",
            "Epoch  61: Train 0.6535, Test 1.4264 → saved best\n",
            "Epoch  62: Train 0.4330, Test 1.2533 → saved best\n",
            "Epoch  63: Train 0.3922, Test 1.3801 → saved best\n",
            "Epoch  64: Train 0.3195, Test 1.1938 → saved best\n",
            "Epoch  65: Train 0.3469, Test 1.0364 \n",
            "Epoch  66: Train 0.3020, Test 0.9281 → saved best\n",
            "Epoch  67: Train 0.3067, Test 1.1002 \n",
            "Epoch  68: Train 0.2453, Test 1.0517 → saved best\n",
            "Epoch  69: Train 0.3020, Test 0.8618 \n",
            "Epoch  70: Train 0.2307, Test 0.8923 → saved best\n",
            "Epoch  71: Train 0.1872, Test 0.8079 → saved best\n",
            "Epoch  72: Train 0.2998, Test 1.4952 \n",
            "Epoch  73: Train 0.1906, Test 1.2807 \n",
            "Epoch  74: Train 0.1930, Test 1.3610 \n",
            "Epoch  75: Train 0.1963, Test 1.3536 \n",
            "Epoch  76: Train 0.1740, Test 1.1724 → saved best\n",
            "Epoch  77: Train 0.2236, Test 1.1175 \n",
            "Epoch  78: Train 0.1876, Test 1.1118 \n",
            "Epoch  79: Train 0.1826, Test 1.2019 \n",
            "Epoch  80: Train 0.1833, Test 0.9864 \n",
            "Epoch  81: Train 0.1560, Test 1.0025 → saved best\n",
            "Epoch  82: Train 0.1993, Test 0.9803 \n",
            "Epoch  83: Train 0.2105, Test 1.0147 \n",
            "Epoch  84: Train 0.1889, Test 0.8546 \n",
            "Epoch  85: Train 0.1398, Test 0.8125 → saved best\n",
            "Epoch  86: Train 0.1602, Test 0.7548 \n",
            "Epoch  87: Train 0.1478, Test 0.7230 \n",
            "Epoch  88: Train 0.1600, Test 0.7768 \n",
            "Epoch  89: Train 0.1356, Test 0.6578 → saved best\n",
            "Epoch  90: Train 0.1309, Test 0.6899 → saved best\n",
            "Epoch  91: Train 0.1414, Test 0.5725 \n",
            "Epoch  92: Train 0.1611, Test 0.6364 \n",
            "Epoch  93: Train 0.1508, Test 0.7351 \n",
            "Epoch  94: Train 0.1172, Test 0.5874 → saved best\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-73-1314512105.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mXb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best_train_loss = float('inf')\n",
        "print('Starting Training Loop')\n",
        "\n",
        "# 4) Training loop with device‐moves\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # -- Train --\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for Xb, yb in train_loader:\n",
        "        Xb, yb = Xb.to(device), yb.to(device)    # Xb is (batch, 1, 36, 350)\n",
        "        preds  = model(Xb)                      # no more unpacking error\n",
        "        loss   = criterion(preds, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * Xb.size(0)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # -- Evaluate --\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in test_loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            test_loss += criterion(model(Xb), yb).item() * Xb.size(0)\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    # -- Checkpoint --\n",
        "    if train_loss < best_train_loss:\n",
        "        best_train_loss = train_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        status = '→ saved best'\n",
        "    else:\n",
        "        status = ''\n",
        "    print(f\"Epoch {epoch:3d}: Train {train_loss:.4f}, Test {test_loss:.4f} {status}\")\n",
        "\n",
        "print(\"Training complete. Best test loss:\", best_train_loss)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}