{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOShGppzKsr4alsAH0McmJ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eric-rWang/VivoX/blob/main/PPG_VivoX_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PPG Array Transformer for Arterial/Venous SpO₂ Prediction"
      ],
      "metadata": {
        "id": "yAVr_4BBg1rM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBGFNr28gt_J",
        "outputId": "6758b3fb-7745-4227-90f9-7f3b872064e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.14.0)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from h5py) (2.0.2)\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pip install h5py torchsummary\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchsummary import summary\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading + Preprocessing"
      ],
      "metadata": {
        "id": "gqRzWeObg59q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PPGDataset(Dataset):\n",
        "    \"\"\"Loads PPG array data from HDF5 files\"\"\"\n",
        "    def __init__(self, file_path, augment=True, test_mode=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            file_path (string): Path to the HDF5 file\n",
        "            augment (bool): Whether to apply data augmentation\n",
        "            test_mode (bool): If True, returns additional metadata for testing\n",
        "        \"\"\"\n",
        "        with h5py.File(file_path, 'r') as f:\n",
        "            self.waveforms = f['waveforms'][:]\n",
        "            self.labels = f['labels'][:]\n",
        "\n",
        "        self.augment = augment\n",
        "        self.test_mode = test_mode\n",
        "\n",
        "        # Add placeholder for metadata if in test mode\n",
        "        if test_mode:\n",
        "            self.positions = np.zeros((len(self.waveforms), 2))  # [arterial_pos, venous_pos]\n",
        "            self.spacings = np.zeros(len(self.waveforms))        # vessel spacing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.waveforms)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.waveforms[idx].astype(np.float32)\n",
        "        y = self.labels[idx].astype(np.float32)\n",
        "\n",
        "        if self.augment:\n",
        "            x = self.augment_sample(x)\n",
        "\n",
        "        if self.test_mode:\n",
        "            return torch.tensor(x), torch.tensor(y), torch.tensor(self.positions[idx]), torch.tensor(self.spacings[idx])\n",
        "        return torch.tensor(x), torch.tensor(y)\n",
        "\n",
        "    def augment_sample(self, x):\n",
        "        \"\"\"Applies physics-based data augmentation\"\"\"\n",
        "        # 1. Random channel shift (simulate sensor placement variation)\n",
        "        if np.random.rand() > 0.5:\n",
        "            shift = np.random.randint(-3, 3)\n",
        "            x = np.roll(x, shift, axis=1)\n",
        "\n",
        "        # 2. Venous signal inversion (randomly apply to 940nm channels)\n",
        "        if np.random.rand() > 0.7:\n",
        "            x[:, 24:] *= -1\n",
        "\n",
        "        # 3. Distance-based signal attenuation\n",
        "        vessel_position = np.random.randint(0, 12)  # Random vessel center\n",
        "        distance = np.abs(np.arange(12) - vessel_position)\n",
        "        decay = np.exp(-distance/2.0)  # Light decay model\n",
        "\n",
        "        # Apply decay to all wavelengths\n",
        "        for i in range(3):\n",
        "            start_idx = i * 12\n",
        "            end_idx = (i + 1) * 12\n",
        "            x[:, start_idx:end_idx] *= decay\n",
        "\n",
        "        # 4. Add wavelength-specific noise\n",
        "        noise_levels = [0.02, 0.015, 0.025]  # 660nm, 850nm, 940nm\n",
        "        for i, noise_level in enumerate(noise_levels):\n",
        "            start_idx = i * 12\n",
        "            end_idx = (i + 1) * 12\n",
        "            noise = np.random.normal(0, noise_level, x[:, start_idx:end_idx].shape)\n",
        "            x[:, start_idx:end_idx] += noise\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Dgpq5iTCg9nj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Architecture"
      ],
      "metadata": {
        "id": "RfKh7mTfhJAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Create positional encoding buffer\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        # FIXED: Corrected div_term calculation with proper parentheses\n",
        "        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * (-math.log(10000.0) / self.d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        if seq_len > self.max_len:\n",
        "            # Dynamically extend positional encoding\n",
        "            self.extend_pe(seq_len)\n",
        "        x = x + self.pe[:seq_len, :].unsqueeze(0)  # Add batch dimension\n",
        "        return self.dropout(x)\n",
        "\n",
        "    def extend_pe(self, seq_len):\n",
        "        \"\"\"Extend positional encoding for longer sequences\"\"\"\n",
        "        position = torch.arange(self.max_len, seq_len).float().unsqueeze(1)\n",
        "        # FIXED: Corrected div_term calculation with proper parentheses\n",
        "        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * (-math.log(10000.0) / self.d_model))\n",
        "        new_pe = torch.zeros(len(position), self.d_model)\n",
        "        new_pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        new_pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.pe = torch.cat([self.pe, new_pe], dim=0)\n",
        "        self.max_len = seq_len\n",
        "\n",
        "\n",
        "# Transformer Model\n",
        "class PPGArrayTransformer(nn.Module):\n",
        "    def __init__(self, d_model=126, nhead=6, num_layers=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Wavelength-specific embedding\n",
        "        self.embed_660 = nn.Linear(1, d_model//3)\n",
        "        self.embed_850 = nn.Linear(1, d_model//3)\n",
        "        self.embed_940 = nn.Linear(1, d_model//3)\n",
        "\n",
        "        # Positional encodings\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_len=5000)\n",
        "\n",
        "        # Learnable PD positions\n",
        "        self.pd_position = nn.Embedding(12, d_model//3)\n",
        "\n",
        "        # Transformers\n",
        "        self.spatial_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=256, dropout=dropout),\n",
        "            num_layers=1\n",
        "        )\n",
        "        self.temporal_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=512, dropout=dropout),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "        # Venous presence detector\n",
        "        self.venous_detector = nn.Sequential(\n",
        "            nn.Linear(d_model, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Output heads\n",
        "        self.art_head = nn.Sequential(\n",
        "            nn.Linear(d_model, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "        self.ven_head = nn.Sequential(\n",
        "            nn.Linear(d_model, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        # Split into wavelengths\n",
        "        x_660 = x[:, :, :12].unsqueeze(-1)  # (batch, 350, 12, 1)\n",
        "        x_850 = x[:, :, 12:24].unsqueeze(-1)\n",
        "        x_940 = x[:, :, 24:].unsqueeze(-1)\n",
        "\n",
        "        # PD position embeddings\n",
        "        pd_indices = torch.arange(12).to(x.device)\n",
        "        pd_emb = self.pd_position(pd_indices)  # (12, d_model//3)\n",
        "        pd_emb = pd_emb.unsqueeze(0).unsqueeze(0)  # (1, 1, 12, d_model//3)\n",
        "\n",
        "        # Embed each wavelength\n",
        "        emb_660 = self.embed_660(x_660) + pd_emb\n",
        "        emb_850 = self.embed_850(x_850) + pd_emb\n",
        "        emb_940 = self.embed_940(x_940) + pd_emb\n",
        "\n",
        "        # Combine embeddings\n",
        "        x = torch.cat([emb_660, emb_850, emb_940], dim=-1)  # (batch, 350, 12, d_model)\n",
        "\n",
        "        # Combine time and PD dimensions\n",
        "        x = x.reshape(batch_size, seq_len * 12, self.d_model)  # (batch, 4200, d_model)\n",
        "        x = self.pos_encoder(x)\n",
        "\n",
        "        # Transformer processing\n",
        "        x = x.permute(1, 0, 2)  # (4200, batch, d_model)\n",
        "        x = self.spatial_transformer(x)\n",
        "        temporal_out = self.temporal_transformer(x)\n",
        "        temporal_out = temporal_out.permute(1, 0, 2)  # (batch, 4200, d_model)\n",
        "\n",
        "        # Venous presence weighting\n",
        "        venous_mask = self.venous_detector(temporal_out)  # (batch, 4200, 1)\n",
        "        temporal_out = temporal_out * venous_mask  # Automatic broadcasting\n",
        "\n",
        "        # Global pooling\n",
        "        pooled = temporal_out.mean(dim=1)  # (batch, d_model)\n",
        "\n",
        "        # Predictions\n",
        "        art_pred = self.art_head(pooled)\n",
        "        ven_pred = self.ven_head(pooled)\n",
        "\n",
        "        return torch.cat([art_pred, ven_pred], dim=1), venous_mask"
      ],
      "metadata": {
        "id": "I642RX2ShKul"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Setup"
      ],
      "metadata": {
        "id": "dLNq68oMhOCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def physiological_loss(art_pred, ven_pred, art_true, ven_true):\n",
        "    \"\"\"Custom loss with physiological constraints\"\"\"\n",
        "    # Base MSE losses\n",
        "    art_loss = F.mse_loss(art_pred, art_true)\n",
        "    ven_loss = F.mse_loss(ven_pred, ven_true)\n",
        "\n",
        "    # Physiological constraint: venous SpO₂ < arterial SpO₂\n",
        "    violation = torch.relu(ven_pred - art_pred)\n",
        "    constraint_loss = torch.mean(violation) * 0.5\n",
        "\n",
        "    return art_loss + ven_loss + constraint_loss\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=50, lr=1e-4):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_epoch_loss = 0\n",
        "        for batch_x, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            # FIX: Properly handle model output\n",
        "            output, _ = model(batch_x)\n",
        "            art_pred = output[:, 0]\n",
        "            ven_pred = output[:, 1]\n",
        "\n",
        "            art_true, ven_true = batch_y[:, 0], batch_y[:, 1]\n",
        "\n",
        "            loss = physiological_loss(art_pred, ven_pred, art_true, ven_true)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_epoch_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_epoch_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_x, batch_y in val_loader:\n",
        "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "                # FIX: Properly handle model output\n",
        "                output, _ = model(batch_x)\n",
        "                art_pred = output[:, 0]\n",
        "                ven_pred = output[:, 1]\n",
        "\n",
        "                art_true, ven_true = batch_y[:, 0], batch_y[:, 1]\n",
        "\n",
        "                loss = physiological_loss(art_pred, ven_pred, art_true, ven_true)\n",
        "                val_epoch_loss += loss.item()\n",
        "\n",
        "        # Calculate epoch metrics (unchanged)\n",
        "        train_epoch_loss /= len(train_loader)\n",
        "        val_epoch_loss /= len(val_loader)\n",
        "        train_losses.append(train_epoch_loss)\n",
        "        val_losses.append(val_epoch_loss)\n",
        "\n",
        "        # Update scheduler\n",
        "        scheduler.step(val_epoch_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_epoch_loss:.4f}, Val Loss: {val_epoch_loss:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_epoch_loss < best_val_loss:\n",
        "            best_val_loss = val_epoch_loss\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "            print(\"Saved new best model\")\n",
        "\n",
        "    # Plot training history (unchanged)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training History')\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Shbfbu0QhPOK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Metrics"
      ],
      "metadata": {
        "id": "2UmXOQMfhR-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "\n",
        "    art_preds, art_trues = [], []\n",
        "    ven_preds, ven_trues = [], []\n",
        "    venous_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in test_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            # FIX: Properly handle model output\n",
        "            output, venous_mask = model(batch_x)\n",
        "            art_pred = output[:, 0]\n",
        "            ven_pred = output[:, 1]\n",
        "\n",
        "            art_preds.append(art_pred.cpu().numpy())\n",
        "            ven_preds.append(ven_pred.cpu().numpy())\n",
        "            art_trues.append(batch_y[:, 0].cpu().numpy())\n",
        "            ven_trues.append(batch_y[:, 1].cpu().numpy())\n",
        "            venous_scores.append(venous_mask.cpu().numpy())\n",
        "\n",
        "    # Concatenate results (unchanged)\n",
        "    art_preds = np.concatenate(art_preds)\n",
        "    ven_preds = np.concatenate(ven_preds)\n",
        "    art_trues = np.concatenate(art_trues)\n",
        "    ven_trues = np.concatenate(ven_trues)\n",
        "    venous_scores = np.concatenate(venous_scores)\n",
        "\n",
        "    # Calculate metrics (unchanged)\n",
        "    art_mae = np.mean(np.abs(art_preds - art_trues))\n",
        "    ven_mae = np.mean(np.abs(ven_preds - ven_trues))\n",
        "    art_rmse = np.sqrt(np.mean((art_preds - art_trues)**2))\n",
        "    ven_rmse = np.sqrt(np.mean((ven_preds - ven_trues)**2))\n",
        "\n",
        "    print(f\"Arterial SpO₂ - MAE: {art_mae:.2f}%, RMSE: {art_rmse:.2f}%\")\n",
        "    print(f\"Venous SpO₂   - MAE: {ven_mae:.2f}%, RMSE: {ven_rmse:.2f}%\")\n",
        "\n",
        "    # Plot results (unchanged)\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(art_trues, art_preds, alpha=0.5)\n",
        "    plt.plot([50, 100], [50, 100], 'r--')\n",
        "    plt.xlabel('True Arterial SpO₂ (%)')\n",
        "    plt.ylabel('Predicted Arterial SpO₂ (%)')\n",
        "    plt.title(f'Arterial SpO₂ Prediction (MAE: {art_mae:.2f}%)')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.scatter(ven_trues, ven_preds, alpha=0.5)\n",
        "    plt.plot([30, 80], [30, 80], 'r--')\n",
        "    plt.xlabel('True Venous SpO₂ (%)')\n",
        "    plt.ylabel('Predicted Venous SpO₂ (%)')\n",
        "    plt.title(f'Venous SpO₂ Prediction (MAE: {ven_mae:.2f}%)')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('spO2_predictions.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot venous detection scores (unchanged)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(venous_scores, bins=50, alpha=0.7)\n",
        "    plt.axvline(0.5, color='r', linestyle='--')\n",
        "    plt.xlabel('Venous Presence Score')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Venous Signal Detection Distribution')\n",
        "    plt.savefig('venous_detection.png')\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'art_mae': art_mae,\n",
        "        'ven_mae': ven_mae,\n",
        "        'art_rmse': art_rmse,\n",
        "        'ven_rmse': ven_rmse,\n",
        "        'venous_scores': venous_scores\n",
        "    }"
      ],
      "metadata": {
        "id": "AFdMhGEghToY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Workflow"
      ],
      "metadata": {
        "id": "8s3_zVQGhX2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Configuration\n",
        "    DATA_PATH = \"Shifting_Position_v3.3.h5\"  # Update this path\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCHS = 100\n",
        "    LR = 1e-4\n",
        "    TEST_SIZE = 0.2\n",
        "    VAL_SIZE = 0.1\n",
        "\n",
        "    # Load dataset\n",
        "    full_dataset = PPGDataset(DATA_PATH, augment=True)\n",
        "\n",
        "    # Split into train/val/test\n",
        "    train_idx, test_idx = train_test_split(\n",
        "        range(len(full_dataset)),\n",
        "        test_size=TEST_SIZE,\n",
        "        random_state=42\n",
        "    )\n",
        "    train_idx, val_idx = train_test_split(\n",
        "        train_idx,\n",
        "        test_size=VAL_SIZE/(1-TEST_SIZE),\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Create subsets\n",
        "    train_dataset = torch.utils.data.Subset(full_dataset, train_idx)\n",
        "    val_dataset = torch.utils.data.Subset(full_dataset, val_idx)\n",
        "    test_dataset = torch.utils.data.Subset(full_dataset, test_idx)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Initialize model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = PPGArrayTransformer(d_model=126, nhead=6, num_layers=4).to(device)\n",
        "\n",
        "    # Print model summary\n",
        "    # summary(model, input_size=(350, 36))\n",
        "\n",
        "    # Train model\n",
        "    trained_model = train_model(model, train_loader, val_loader, epochs=EPOCHS, lr=LR)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    results = evaluate_model(trained_model, test_loader)\n",
        "\n",
        "    # Save final model\n",
        "    torch.save(trained_model.state_dict(), \"final_model.pth\")\n",
        "    print(\"Training complete. Model saved.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3oTf4mlhZJf",
        "outputId": "866bcb92-1687-4f78-f57d-b9568ad2df1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "Epoch 1/100: 100%|██████████| 113/113 [10:53<00:00,  5.79s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100 - Train Loss: 11904.1403, Val Loss: 11028.0198\n",
            "Saved new best model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/100: 100%|██████████| 113/113 [10:54<00:00,  5.79s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/100 - Train Loss: 10221.4757, Val Loss: 9152.7883\n",
            "Saved new best model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/100: 100%|██████████| 113/113 [10:54<00:00,  5.79s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/100 - Train Loss: 8161.2056, Val Loss: 6980.5519\n",
            "Saved new best model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/100: 100%|██████████| 113/113 [10:53<00:00,  5.79s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/100 - Train Loss: 5973.0540, Val Loss: 4868.3383\n",
            "Saved new best model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/100: 100%|██████████| 113/113 [10:53<00:00,  5.79s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/100 - Train Loss: 3998.5876, Val Loss: 3105.6494\n",
            "Saved new best model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/100: 100%|██████████| 113/113 [10:53<00:00,  5.78s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/100 - Train Loss: 2445.2392, Val Loss: 1807.5715\n",
            "Saved new best model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/100: 100%|██████████| 113/113 [10:53<00:00,  5.78s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/100 - Train Loss: 1363.8363, Val Loss: 962.8081\n",
            "Saved new best model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/100: 100%|██████████| 113/113 [10:53<00:00,  5.78s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/100 - Train Loss: 711.6155, Val Loss: 503.1525\n",
            "Saved new best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100: 100%|██████████| 113/113 [10:53<00:00,  5.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100 - Train Loss: 388.6825, Val Loss: 303.7620\n",
            "Saved new best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100: 100%|██████████| 113/113 [10:53<00:00,  5.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 - Train Loss: 261.7249, Val Loss: 237.0788\n",
            "Saved new best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100: 100%|██████████| 113/113 [10:53<00:00,  5.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100 - Train Loss: 221.6928, Val Loss: 218.7762\n",
            "Saved new best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100: 100%|██████████| 113/113 [10:53<00:00,  5.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100 - Train Loss: 211.6535, Val Loss: 215.8425\n",
            "Saved new best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/100: 100%|██████████| 113/113 [10:53<00:00,  5.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100 - Train Loss: 209.9357, Val Loss: 214.9667\n",
            "Saved new best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/100: 100%|██████████| 113/113 [10:53<00:00,  5.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100 - Train Loss: 209.9053, Val Loss: 215.1142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/100: 100%|██████████| 113/113 [10:53<00:00,  5.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100 - Train Loss: 209.8776, Val Loss: 215.2351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/100:  12%|█▏        | 14/113 [01:21<09:34,  5.81s/it]"
          ]
        }
      ]
    }
  ]
}